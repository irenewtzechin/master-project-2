#!/usr/bin/env python
# coding: utf-8

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv("full_prep_set.csv") 

# Convert Type to numerical value
# 0: Normal 1: Abnormal

for index, row in data.iterrows():
    if(data.at[index,'Type'] == 'N'):
        data.at[index,'Type'] = 0
    else:
        data.at[index,'Type'] = 1
data = data.astype({'Type': int})

# Creating train data with 80% values of original dataframe
train_data_1 = data.groupby('Type', group_keys=False).apply(lambda x: x.sample(frac=0.8))

# Creating test data with rest of the 20% values
test_data_1= data.drop(train_data_1.index)

# Save
train_signal_1 = train_data_1.to_csv("train_signal_1.csv", index=False) # train data
test_signal_1 = test_data_1.to_csv("test_signal_1.csv", index=False) # test data

from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical
import tensorflow as tf
import numpy as np
from sklearn.model_selection import train_test_split

# Simple ANN
X1, y1 = train_data_1.iloc[: , :250].values,train_data_1['Type'].values
X1, valX1, y1, valy1= train_test_split(X1,y1,test_size=0.2)
testX1, testy1 = test_data_1.iloc[: , :250].values, test_data_1['Type'].values

y1 = to_categorical(y1, num_classes = 2)
valy1 = to_categorical(valy1, num_classes = 2)
testy1  = to_categorical(testy1, num_classes = 2)

print("X1 shape=" +str(X1.shape))
print("y1 shape=" +str(y1.shape))
print("valX1 shape=" +str(valX1.shape))
print("valy1 shape=" +str(valy1.shape))
print("testX1 shape=" +str(testX1.shape))
print("testy1 shape=" +str(testy1.shape)+'\n')

ann_model_1 = Sequential()
ann_model_1.add(Dense(50, activation='relu', input_shape=(250,)))
ann_model_1.add(Dense(50, activation='relu'))
ann_model_1.add(Dense(50, activation='relu'))
ann_model_1.add(Dense(50, activation='relu'))
ann_model_1.add(Dense(2, activation='softmax'))

ann_model_1.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])

ann_model_1.summary()

ann_model_history =  ann_model_1.fit(X1, y1, epochs = 15, batch_size = 32, validation_data=(valX1, valy1))

plt.plot(ann_model_history.history['accuracy'])
plt.plot(ann_model_history.history['val_accuracy'])
plt.legend(["accuracy","val_accuracy"])
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

plt.plot(ann_model_history.history['loss'])
plt.plot(ann_model_history.history['val_loss'])
plt.legend(["loss","val_loss"])
plt.xlabel('Epoch')
plt.ylabel('Loss')

ann_model_1.evaluate(testX1, testy1)

# Make Prediction
predict = ann_model_1.predict(testX1)
predict

# distributional probability to integers
yhat = np.argmax(predict, axis = 1)

from sklearn.metrics import classification_report, confusion_matrix
confusion_matrix(np.argmax(testy1, axis = 1), yhat)
print(classification_report(np.argmax(testy1, axis=1), yhat))
